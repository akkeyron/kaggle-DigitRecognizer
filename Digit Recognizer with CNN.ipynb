{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loqma\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:35: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\loqma\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:597: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\Users\\loqma\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:836: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\Users\\loqma\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "C:\\Users\\loqma\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1097: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\loqma\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1344: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\loqma\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1480: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "C:\\Users\\loqma\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:152: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  precompute=False, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\loqma\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:320: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, random_state=None,\n",
      "C:\\Users\\loqma\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:580: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=4 * np.finfo(np.float).eps, n_jobs=None,\n",
      "C:\\Users\\loqma\\Miniconda3\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:31: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer, RobustScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0          1       0       0       0       0       0       0       0       0   \n",
       "1          0       0       0       0       0       0       0       0       0   \n",
       "2          1       0       0       0       0       0       0       0       0   \n",
       "3          4       0       0       0       0       0       0       0       0   \n",
       "4          0       0       0       0       0       0       0       0       0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "41995      0       0       0       0       0       0       0       0       0   \n",
       "41996      1       0       0       0       0       0       0       0       0   \n",
       "41997      7       0       0       0       0       0       0       0       0   \n",
       "41998      6       0       0       0       0       0       0       0       0   \n",
       "41999      9       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0           0  ...         0         0         0         0         0   \n",
       "1           0  ...         0         0         0         0         0   \n",
       "2           0  ...         0         0         0         0         0   \n",
       "3           0  ...         0         0         0         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "41995       0  ...         0         0         0         0         0   \n",
       "41996       0  ...         0         0         0         0         0   \n",
       "41997       0  ...         0         0         0         0         0   \n",
       "41998       0  ...         0         0         0         0         0   \n",
       "41999       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0             0         0         0         0         0  \n",
       "1             0         0         0         0         0  \n",
       "2             0         0         0         0         0  \n",
       "3             0         0         0         0         0  \n",
       "4             0         0         0         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "41995         0         0         0         0         0  \n",
       "41996         0         0         0         0         0  \n",
       "41997         0         0         0         0         0  \n",
       "41998         0         0         0         0         0  \n",
       "41999         0         0         0         0         0  \n",
       "\n",
       "[42000 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type casting into float32 to reduce memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.astype('float32')\n",
    "test = test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: float32(785)\n",
      "memory usage: 125.8 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the first 40 digit for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 40 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_digits(data):\n",
    "    fig, axes = plt.subplots(4, 10, figsize=(10, 4),\n",
    "                             subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                             gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(data[i].reshape(28, 28),\n",
    "                  cmap='binary', interpolation='nearest',\n",
    "                  clim=(0, 16))\n",
    "plot_digits(train.drop('label', axis=1).to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop('label', axis=1)\n",
    "y = train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert output into 10 class matrices\n",
    "y = keras.utils.to_categorical(np.squeeze(y), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the array for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to_numpy()\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_val = X_val.to_numpy()\n",
    "X_val = X_val.reshape(X_val.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31500, 28, 28, 1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31500, 10)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron\n",
    "\n",
    "## Architecture\n",
    "- One convolutional layer (6x6 convolution) \n",
    "- Max pooling to reduce the size by a factor of 2 in each axis\n",
    "- Two hidden layers with 2x and x nodes with relu\n",
    "- 10 nodes output layer with softmax since we have 10 possible outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define MLP model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(6, kernel_size = (6, 6),\n",
    "                activation = 'relu',\n",
    "                input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(40, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000016565560F28> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000016565560F28> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "984/985 [============================>.] - ETA: 0s - loss: 1.5608 - accuracy: 0.5124WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000016565560488> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000016565560488> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 1.5606 - accuracy: 0.5125 - val_loss: 0.8270 - val_accuracy: 0.7138\n",
      "Epoch 2/25\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.4017 - accuracy: 0.8856 - val_loss: 0.2187 - val_accuracy: 0.9423\n",
      "Epoch 3/25\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1634 - accuracy: 0.9569 - val_loss: 0.1650 - val_accuracy: 0.9570\n",
      "Epoch 4/25\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.1141 - accuracy: 0.9681 - val_loss: 0.1312 - val_accuracy: 0.9648\n",
      "Epoch 5/25\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.0880 - accuracy: 0.9740 - val_loss: 0.1292 - val_accuracy: 0.9651\n",
      "Epoch 6/25\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.0757 - accuracy: 0.9778 - val_loss: 0.1337 - val_accuracy: 0.9637\n",
      "Epoch 7/25\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.0644 - accuracy: 0.9799 - val_loss: 0.1200 - val_accuracy: 0.9680\n",
      "Epoch 8/25\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.0523 - accuracy: 0.9841 - val_loss: 0.1065 - val_accuracy: 0.9709\n",
      "Epoch 9/25\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.0452 - accuracy: 0.9863 - val_loss: 0.1201 - val_accuracy: 0.9706\n",
      "Epoch 10/25\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.0388 - accuracy: 0.9877 - val_loss: 0.1164 - val_accuracy: 0.9711\n",
      "Epoch 11/25\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.0333 - accuracy: 0.9897 - val_loss: 0.1361 - val_accuracy: 0.9707\n",
      "Epoch 12/25\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.0297 - accuracy: 0.9907 - val_loss: 0.1365 - val_accuracy: 0.9704\n",
      "Epoch 13/25\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.0325 - accuracy: 0.9908 - val_loss: 0.1553 - val_accuracy: 0.9701\n",
      "Epoch 14/25\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.0261 - accuracy: 0.9919 - val_loss: 0.1265 - val_accuracy: 0.9740\n",
      "Epoch 15/25\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.0212 - accuracy: 0.9933 - val_loss: 0.1371 - val_accuracy: 0.9714\n",
      "Epoch 16/25\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.0193 - accuracy: 0.9938 - val_loss: 0.1340 - val_accuracy: 0.9756\n",
      "Epoch 17/25\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.0210 - accuracy: 0.9937 - val_loss: 0.1604 - val_accuracy: 0.9713\n",
      "Epoch 18/25\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.0225 - accuracy: 0.9932 - val_loss: 0.1352 - val_accuracy: 0.9734\n",
      "Epoch 19/25\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.0177 - accuracy: 0.9948 - val_loss: 0.1323 - val_accuracy: 0.9760\n",
      "Epoch 20/25\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.1407 - val_accuracy: 0.9751\n",
      "Epoch 21/25\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.0189 - accuracy: 0.9945 - val_loss: 0.1416 - val_accuracy: 0.9760\n",
      "Epoch 22/25\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.0162 - accuracy: 0.9954 - val_loss: 0.1618 - val_accuracy: 0.9724\n",
      "Epoch 23/25\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.0139 - accuracy: 0.9955 - val_loss: 0.1888 - val_accuracy: 0.9718\n",
      "Epoch 24/25\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.0197 - accuracy: 0.9946 - val_loss: 0.1666 - val_accuracy: 0.9743\n",
      "Epoch 25/25\n",
      "985/985 [==============================] - 4s 4ms/step - loss: 0.0144 - accuracy: 0.9958 - val_loss: 0.1597 - val_accuracy: 0.9755\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "history = model.fit(X_train, y_train,\n",
    "              batch_size=32,\n",
    "              epochs=25,\n",
    "              verbose=1,\n",
    "              validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.007738640531897545\n",
      "Train accuracy: 0.9974920749664307\n",
      "Test loss: 0.15972335636615753\n",
      "Test accuracy: 0.975523829460144\n"
     ]
    }
   ],
   "source": [
    "# print train and test losses and classification accuracies\n",
    "score = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Train loss:', score[0])\n",
    "print('Train accuracy:', score[1])\n",
    "score = model.evaluate(X_val, y_val, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.reshape(test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict test dataset with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875/875 [==============================] - 2s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=pd.DataFrame(y_pred)\n",
    "sub_df=pd.read_csv('sample_submission.csv')\n",
    "datasets=pd.concat([sub_df['ImageId'],pred],axis=1)\n",
    "datasets.columns=['ImageId','Label']\n",
    "datasets.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>27996</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>27997</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>27998</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>27999</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>28000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ImageId  Label\n",
       "0            1      2\n",
       "1            2      0\n",
       "2            3      9\n",
       "3            4      9\n",
       "4            5      3\n",
       "...        ...    ...\n",
       "27995    27996      9\n",
       "27996    27997      7\n",
       "27997    27998      3\n",
       "27998    27999      9\n",
       "27999    28000      2\n",
       "\n",
       "[28000 rows x 2 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
